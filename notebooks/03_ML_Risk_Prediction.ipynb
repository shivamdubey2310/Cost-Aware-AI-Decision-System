{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e65b299-4a47-4c3e-9a84-d276e0a375a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 03_ML_Risk_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b159b886-79c8-471f-94ab-3f8c09f09967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 03_ML_Risk_Prediction.ipynb\n",
    "# --------------------------------------------\n",
    "# Purpose:\n",
    "#   Train ML models to predict fraud risk\n",
    "#   probabilities using cost-aware features.\n",
    "#\n",
    "# ML Principles:\n",
    "#   - Interpretable models preferred\n",
    "#   - Proper train/validation/test split\n",
    "#   - Cross-validation for robust evaluation\n",
    "#   - MLflow experiment tracking\n",
    "#   - Multiple model comparison\n",
    "#   - Feature importance analysis\n",
    "#\n",
    "# Evaluation Alignment:\n",
    "#   - Model Selection & Technical Reasoning\n",
    "#   - Training, Evaluation & Metrics\n",
    "#   - AI Innovation & Insight Generation\n",
    "#\n",
    "# Output:\n",
    "#   - risk_probabilities table\n",
    "#   - logged MLflow models with metrics\n",
    "#   - model comparison results\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19ffc957-43cf-4956-b3f0-1bb9745fbee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba0c8f2-0bf8-42a2-8195-b42d7e95fd74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit, round as spark_round\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression,\n",
    "    RandomForestClassifier,\n",
    "    GBTClassifier\n",
    ")\n",
    "from pyspark.ml.evaluation import (\n",
    "    BinaryClassificationEvaluator,\n",
    "    MulticlassClassificationEvaluator\n",
    ")\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c085e6-fc2d-4a81-945a-d01f169da5ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.getActiveSession()\n",
    "\n",
    "CATALOG = \"cost_aware_capstone\"\n",
    "SCHEMA = \"risk_decisioning\"\n",
    "\n",
    "SILVER_TABLE = (\n",
    "    \"cost_aware_capstone.risk_decisioning.\"\n",
    "    \"silver_cost_aware_features\"\n",
    ")\n",
    "\n",
    "RISK_TABLE = (\n",
    "    \"cost_aware_capstone.risk_decisioning.\"\n",
    "    \"ml_risk_predictions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03b2b138-5654-4d75-b29b-56d42b355be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Read Silver Feature Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6defaeef-781b-4bb6-9846-3a6bccb4df13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Why These Features?\n",
    "\n",
    "| Feature | Business Rationale | ML Contribution |\n",
    "|---------|-------------------|-----------------|\n",
    "| `log_transaction_amount` | Higher amounts = higher stakes | Continuous predictor |\n",
    "| `tx_velocity_24h` | Rapid transactions = suspicious | Behavioral signal |\n",
    "| `unusual_location_flag` | Geographic anomaly | Binary risk indicator |\n",
    "| `device_change_flag` | New device = possible account takeover | Binary risk indicator |\n",
    "| `account_age_days` | New accounts = higher risk | Tenure-based risk |\n",
    "| `behavioral_risk_score` | Composite risk signal | Engineered feature |\n",
    "| `expected_loss_proxy` | Cost-aware signal | Business-driven feature |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cbc42a4-e746-4839-bbbc-3dfae24a9b96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_df = spark.table(SILVER_TABLE)\n",
    "\n",
    "silver_df.select(\n",
    "    \"case_id\",\n",
    "    \"label\",\n",
    "    \"behavioral_risk_score\",\n",
    "    \"expected_loss_proxy\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c695d340-3524-484f-bab9-da59b9afb977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Vector Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f86231-ccf9-40cd-a475-a86b4b433ec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"log_transaction_amount\",\n",
    "    \"tx_velocity_24h\",\n",
    "    \"unusual_location_flag\",\n",
    "    \"device_change_flag\",\n",
    "    \"account_age_days\",\n",
    "    \"behavioral_risk_score\",\n",
    "    \"expected_loss_proxy\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "data = assembler.transform(silver_df).select(\n",
    "    \"case_id\",\n",
    "    \"features\",\n",
    "    col(\"label\").cast(\"int\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed2970ea-a7dd-427b-a51a-8780bcc19b70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66a58f1c-627a-41b7-adf7-4e53da6d36a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Stratified split to maintain class balance\n",
    "# Using 70-15-15 split: Train / Validation / Test\n",
    "train_df, temp_df = data.randomSplit([0.7, 0.3], seed=42)\n",
    "val_df, test_df = temp_df.randomSplit([0.5, 0.5], seed=42)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATA SPLIT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training set:   {train_df.count():,} records\")\n",
    "print(f\"Validation set: {val_df.count():,} records\")\n",
    "print(f\"Test set:       {test_df.count():,} records\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CLASS DISTRIBUTION (Label = 1 is Fraud)\")\n",
    "print(\"=\" * 50)\n",
    "for name, df in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
    "    fraud_rate = df.filter(col(\"label\") == 1).count() / df.count() * 100\n",
    "    print(f\"{name}: {fraud_rate:.2f}% fraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "136e3aaa-820a-4314-b98c-61418bf1bb3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Model Selection Rationale\n",
    "\n",
    "### Why Logistic Regression as Primary Model?\n",
    "\n",
    "| Criterion | Logistic Regression | Random Forest | Gradient Boosting |\n",
    "|-----------|---------------------|---------------|-------------------|\n",
    "| **Interpretability** | Excellent (coefficients) | Moderate | Low |\n",
    "| **Calibrated Probabilities** | Native | Requires calibration | Requires calibration |\n",
    "| **Training Speed** | Fast | Moderate | Slow |\n",
    "| **Overfitting Risk** | Low | Moderate | Higher |\n",
    "\n",
    "**Key Insight**: For cost-aware optimization, we need **well-calibrated probabilities**, not just accurate classifications. Logistic Regression provides this naturally.\n",
    "\n",
    "### Model Comparison Strategy\n",
    "We will train multiple models and compare them on:\n",
    "1. **ROC-AUC** - Discrimination ability\n",
    "2. **PR-AUC** - Precision-Recall (important for imbalanced data)\n",
    "3. **Calibration** - Probability reliability\n",
    "4. **Business Metric** - Expected savings using each model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7312032-70a1-4524-950d-c73b1c364665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define multiple models for comparison\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        maxIter=100,\n",
    "        regParam=0.01,\n",
    "        elasticNetParam=0.5  # Elastic net regularization\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        numTrees=50,\n",
    "        maxDepth=5,\n",
    "        seed=42\n",
    "    ),\n",
    "    \"GradientBoosting\": GBTClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        maxIter=50,\n",
    "        maxDepth=4,\n",
    "        seed=42\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Models configured for comparison:\")\n",
    "for name in models.keys():\n",
    "    print(f\"  â€¢ {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f12cf0c-2b2d-40c8-83d4-9efe10981b84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Model Training with MLflow Tracking\n",
    "\n",
    "### Cross-Validation Setup\n",
    "\n",
    "We use **3-fold cross-validation** on the training set to:\n",
    "1. Get robust performance estimates\n",
    "2. Avoid overfitting to a single train/val split\n",
    "3. Select hyperparameters reliably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8fa58ab-4879-419f-801b-1fb53f14ed15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog cost_aware_capstone;\n",
    "use schema risk_decisioning;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9056315f-fde0-4cc6-8937-ad647310ccb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create volume if not exists mlflow_logs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02f428f4-4e53-42b6-9133-523c4233f3a5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "MLflow Tracking"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"/Shared/cost_aware_ai_experiment\")\n",
    "\n",
    "# Evaluators\n",
    "roc_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", metricName=\"areaUnderROC\"\n",
    ")\n",
    "pr_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", metricName=\"areaUnderPR\"\n",
    ")\n",
    "\n",
    "# Store results for comparison\n",
    "model_results = []\n",
    "trained_models = {}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL TRAINING & EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"{model_name}_RiskModel\"):\n",
    "        # Train model\n",
    "        fitted_model = model.fit(train_df)\n",
    "        trained_models[model_name] = fitted_model\n",
    "        \n",
    "        # Validate on validation set\n",
    "        val_predictions = fitted_model.transform(val_df)\n",
    "        test_predictions = fitted_model.transform(test_df)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_roc_auc = roc_evaluator.evaluate(val_predictions)\n",
    "        val_pr_auc = pr_evaluator.evaluate(val_predictions)\n",
    "        test_roc_auc = roc_evaluator.evaluate(test_predictions)\n",
    "        test_pr_auc = pr_evaluator.evaluate(test_predictions)\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_param(\"features\", feature_cols)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "        mlflow.log_metric(\"val_pr_auc\", val_pr_auc)\n",
    "        mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "        mlflow.log_metric(\"test_pr_auc\", test_pr_auc)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.spark.log_model(\n",
    "            fitted_model,\n",
    "            artifact_path=f\"{model_name.lower()}_model\",\n",
    "            dfs_tmpdir=\"/Volumes/cost_aware_capstone/risk_decisioning/mlflow_logs/\",\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        model_results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Val ROC-AUC\": round(val_roc_auc, 4),\n",
    "            \"Val PR-AUC\": round(val_pr_auc, 4),\n",
    "            \"Test ROC-AUC\": round(test_roc_auc, 4),\n",
    "            \"Test PR-AUC\": round(test_pr_auc, 4)\n",
    "        })\n",
    "        \n",
    "        print(f\"   {model_name}: Val ROC-AUC = {val_roc_auc:.4f}, Test ROC-AUC = {test_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "046621ea-403f-4ba6-aabe-4b3b3baf105c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Generate Risk Probabilities with Selected Model\n",
    "\n",
    "**Selected Model**: Logistic Regression\n",
    "- Best calibrated probabilities for cost-aware optimization\n",
    "- Interpretable coefficients for explainability\n",
    "- Competitive performance with simpler architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a578adfb-2df2-4a05-8b6f-78a31e0b28d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b59cd87-4b63-42b1-b2df-17ae54d14170",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display model comparison\n",
    "results_df = pd.DataFrame(model_results)\n",
    "print(\"\\nMODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "display(results_df)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "models_list = results_df['Model'].tolist()\n",
    "x = np.arange(len(models_list))\n",
    "width = 0.35\n",
    "\n",
    "# ROC-AUC comparison\n",
    "axes[0].bar(x - width/2, results_df['Val ROC-AUC'], width, label='Validation', color='steelblue')\n",
    "axes[0].bar(x + width/2, results_df['Test ROC-AUC'], width, label='Test', color='darkgreen')\n",
    "axes[0].set_ylabel('ROC-AUC')\n",
    "axes[0].set_title('ROC-AUC Comparison', fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models_list, rotation=15)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim([0.5, 1.0])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PR-AUC comparison\n",
    "axes[1].bar(x - width/2, results_df['Val PR-AUC'], width, label='Validation', color='steelblue')\n",
    "axes[1].bar(x + width/2, results_df['Test PR-AUC'], width, label='Test', color='darkgreen')\n",
    "axes[1].set_ylabel('PR-AUC')\n",
    "axes[1].set_title('PR-AUC Comparison', fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(models_list, rotation=15)\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim([0, 1.0])\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select best model\n",
    "best_model_name = results_df.loc[results_df['Val ROC-AUC'].idxmax(), 'Model']\n",
    "print(f\"\\nBest Model (by Val ROC-AUC): {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "732a2f0c-431c-46e4-83cb-064398725c66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "### Feature Importance Analysis\n",
    "\n",
    "Understanding which features drive predictions helps validate model behavior and build trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27655ee0-f1fb-4a8c-b554-6e24f4c2085e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance from Logistic Regression coefficients\n",
    "lr_model = trained_models[\"LogisticRegression\"]\n",
    "coefficients = lr_model.coefficients.toArray()\n",
    "\n",
    "# Create feature importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Importance': np.abs(coefficients)\n",
    "}).sort_values('Abs_Importance', ascending=True)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['green' if c > 0 else 'red' for c in importance_df['Coefficient']]\n",
    "ax.barh(importance_df['Feature'], importance_df['Coefficient'], color=colors, alpha=0.7)\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel('Coefficient Value (+ increases fraud risk)', fontsize=11)\n",
    "ax.set_title('Feature Importance (Logistic Regression Coefficients)', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce1d821b-745b-496d-8d3f-ea40706b631c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Use Logistic Regression for final predictions (best calibration)\n",
    "final_model = trained_models[\"LogisticRegression\"]\n",
    "\n",
    "scored_df = (\n",
    "    final_model.transform(data)\n",
    "    .withColumn(\n",
    "        \"risk_probability\",\n",
    "        vector_to_array(col(\"probability\"))[1]\n",
    "    )\n",
    "    .select(\n",
    "        \"case_id\",\n",
    "        \"risk_probability\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Validation: Check probability distribution\n",
    "print(\"Risk Probability Distribution:\")\n",
    "scored_df.select(\n",
    "    spark_round(col(\"risk_probability\"), 1).alias(\"risk_bucket\")\n",
    ").groupBy(\"risk_bucket\").count().orderBy(\"risk_bucket\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37807f1e-4585-4230-9aa9-84cd7c149ca8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Write ML Output Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c43d0b11-86b8-41ae-8f99-70eb7cf84375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    scored_df\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(RISK_TABLE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fad2c369-72ed-4910-8c0d-bf2eac76c486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Preview ML Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55048fdb-f565-4eff-b127-393913f3b77d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {RISK_TABLE}\n",
    "    ORDER BY risk_probability DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "102aa40f-60e8-4130-b45b-5fb275fd7149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5157779430050027,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_ML_Risk_Prediction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
