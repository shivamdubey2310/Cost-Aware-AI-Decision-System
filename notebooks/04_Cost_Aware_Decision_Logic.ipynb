{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e65b299-4a47-4c3e-9a84-d276e0a375a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 04_Cost_Aware_Decision_Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b159b886-79c8-471f-94ab-3f8c09f09967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 04_Cost_Aware_Decision_Logic.ipynb\n",
    "# --------------------------------------------\n",
    "# Purpose:\n",
    "#   Transform ML risk predictions into\n",
    "#   cost-aware investigation decisions\n",
    "#   under limited operational capacity.\n",
    "#\n",
    "# Key Innovation:\n",
    "#   Optimize expected financial savings,\n",
    "#   NOT just prediction accuracy.\n",
    "#\n",
    "# Business Problem:\n",
    "#   - Limited investigators (capacity constraint)\n",
    "#   - Each case has different potential loss\n",
    "#   - Each investigation has a cost\n",
    "#   - Goal: Maximize value captured within capacity\n",
    "#\n",
    "# Evaluation Alignment:\n",
    "#   - AI Innovation & Insight Generation\n",
    "#   - Business Impact & Practical Use\n",
    "#   - Database <-> AI Workflow\n",
    "#\n",
    "# Output:\n",
    "#   - gold_decision_recommendations table\n",
    "#   - Actionable investigate/don't decisions\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19ffc957-43cf-4956-b3f0-1bb9745fbee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba0c8f2-0bf8-42a2-8195-b42d7e95fd74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, when, sum as spark_sum, \n",
    "    avg, count, round as spark_round\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.getActiveSession()\n",
    "\n",
    "CATALOG = \"cost_aware_capstone\"\n",
    "SCHEMA = \"risk_decisioning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c085e6-fc2d-4a81-945a-d01f169da5ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "SILVER_TABLE = (\n",
    "    \"cost_aware_capstone.risk_decisioning.\"\n",
    "    \"silver_cost_aware_features\"\n",
    ")\n",
    "\n",
    "RISK_TABLE = (\n",
    "    \"cost_aware_capstone.risk_decisioning.\"\n",
    "    \"ml_risk_predictions\"\n",
    ")\n",
    "\n",
    "GOLD_TABLE = (\n",
    "    \"cost_aware_capstone.risk_decisioning.\"\n",
    "    \"gold_decision_recommendations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03b2b138-5654-4d75-b29b-56d42b355be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Business Constraints Definition\n",
    "\n",
    "### Operational Reality at NexGen Financial Services (fictional)\n",
    "\n",
    "| Constraint | Value | Rationale |\n",
    "|------------|-------|-----------|\n",
    "| Daily Investigation Capacity | 50 | Limited fraud analyst headcount |\n",
    "| Avg Investigation Time | 45 mins | Manual review process |\n",
    "| Investigation Cost | $75-150 | Labor + system costs |\n",
    "\n",
    "**The Core Challenge**: We receive 500+ alerts daily but can only investigate 50. Which 50 should we choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cbc42a4-e746-4839-bbbc-3dfae24a9b96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Business constraint: How many cases can we investigate daily?\n",
    "DAILY_INVESTIGATION_CAPACITY = 50\n",
    "\n",
    "# Edge case handling: Ensure capacity is valid\n",
    "if DAILY_INVESTIGATION_CAPACITY <= 0:\n",
    "    raise ValueError(\"Investigation capacity must be positive\")\n",
    "\n",
    "print(f\"Daily Investigation Capacity: {DAILY_INVESTIGATION_CAPACITY} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c695d340-3524-484f-bab9-da59b9afb977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "791f85bd-b9da-48da-babd-6b09a371008d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_df = spark.table(SILVER_TABLE)\n",
    "risk_df = spark.table(RISK_TABLE)\n",
    "\n",
    "# Edge case: Check for empty tables\n",
    "silver_count = silver_df.count()\n",
    "risk_count = risk_df.count()\n",
    "\n",
    "if silver_count == 0 or risk_count == 0:\n",
    "    raise ValueError(\"Input tables are empty. Run previous notebooks first.\")\n",
    "\n",
    "print(f\"Silver table records: {silver_count:,}\")\n",
    "print(f\"Risk predictions records: {risk_count:,}\")\n",
    "\n",
    "# Join features with predictions\n",
    "df = (\n",
    "    silver_df\n",
    "    .join(risk_df, on=\"case_id\", how=\"inner\")\n",
    ")\n",
    "\n",
    "join_count = df.count()\n",
    "print(f\"Joined records: {join_count:,}\")\n",
    "\n",
    "# Edge case: Check for data loss in join\n",
    "if join_count < min(silver_count, risk_count) * 0.9:\n",
    "    print(\"WARNING: Significant data loss in join. Check case_id matching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed2970ea-a7dd-427b-a51a-8780bcc19b70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Expected Loss Modeling\n",
    "\n",
    "### The Mathematical Foundation\n",
    "\n",
    "**Traditional Approach** (Risk-First):\n",
    "```\n",
    "Priority = Risk Probability\n",
    "Investigate: Top N by risk score\n",
    "```\n",
    "\n",
    "**Our Cost-Aware Approach**:\n",
    "```\n",
    "Expected Loss if Ignored = P(fraud) Ã— Fraud_Loss_If_Missed\n",
    "Expected Savings if Investigated = Expected_Loss_If_Ignored - Investigation_Cost\n",
    "Priority = Expected Savings\n",
    "```\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "| Case | Risk | Potential Loss | Inv. Cost | Expected Savings | Priority |\n",
    "|------|------|----------------|-----------|------------------|----------|\n",
    "| A | 90% | $500 | $100 | $350 | Lower |\n",
    "| B | 50% | $10,000 | $100 | $4,900 | **Higher** |\n",
    "\n",
    "Case B has lower risk but **much higher expected value** - our system correctly prioritizes it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66a58f1c-627a-41b7-adf7-4e53da6d36a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate expected values\n",
    "decision_df = (\n",
    "    df\n",
    "    # Expected loss if we DON'T investigate\n",
    "    .withColumn(\n",
    "        \"expected_loss_if_ignored\",\n",
    "        col(\"risk_probability\") * col(\"fraud_loss_if_missed\")\n",
    "    )\n",
    "    # Net expected savings from investigating\n",
    "    # (what we save minus what it costs to investigate)\n",
    "    .withColumn(\n",
    "        \"expected_savings_if_investigated\",\n",
    "        col(\"expected_loss_if_ignored\") - col(\"investigation_cost\")\n",
    "    )\n",
    "    # Edge case: Flag negative savings cases\n",
    "    .withColumn(\n",
    "        \"worth_investigating\",\n",
    "        col(\"expected_savings_if_investigated\") > 0\n",
    "    )\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"EXPECTED VALUE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "decision_df.select(\n",
    "    spark_round(avg(\"expected_loss_if_ignored\"), 2).alias(\"avg_expected_loss\"),\n",
    "    spark_round(avg(\"expected_savings_if_investigated\"), 2).alias(\"avg_expected_savings\"),\n",
    "    spark_sum(when(col(\"worth_investigating\"), 1).otherwise(0)).alias(\"cases_worth_investigating\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "136e3aaa-820a-4314-b98c-61418bf1bb3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Optimization: Rank by Financial Impact\n",
    "\n",
    "### Greedy Optimization\n",
    "\n",
    "For a single capacity constraint with linear objective, **greedy selection is optimal**:\n",
    "\n",
    "1. Rank all cases by expected savings (descending)\n",
    "2. Select top K cases (K = capacity)\n",
    "3. This maximizes total expected savings\n",
    "\n",
    "**Mathematical Proof**: This is a special case of the Knapsack problem where all items have the same \"weight\" (one investigation slot each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7312032-70a1-4524-950d-c73b1c364665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rank by expected savings (descending = highest value first)\n",
    "window_spec = Window.orderBy(\n",
    "    col(\"expected_savings_if_investigated\").desc()\n",
    ")\n",
    "\n",
    "ranked_df = (\n",
    "    decision_df\n",
    "    .withColumn(\"priority_rank\", row_number().over(window_spec))\n",
    ")\n",
    "\n",
    "# Show top 5 highest-value cases\n",
    "print(\"TOP 5 HIGHEST-VALUE CASES\")\n",
    "ranked_df.select(\n",
    "    \"case_id\", \n",
    "    spark_round(\"risk_probability\", 3).alias(\"risk\"),\n",
    "    spark_round(\"fraud_loss_if_missed\", 2).alias(\"potential_loss\"),\n",
    "    spark_round(\"expected_savings_if_investigated\", 2).alias(\"expected_savings\"),\n",
    "    \"priority_rank\"\n",
    ").filter(col(\"priority_rank\") <= 5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f12cf0c-2b2d-40c8-83d4-9efe10981b84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Apply Capacity Constraint (Optimization Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8fa58ab-4879-419f-801b-1fb53f14ed15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply capacity constraint: Investigate top K cases\n",
    "final_df = (\n",
    "    ranked_df\n",
    "    .withColumn(\n",
    "        \"decision\",\n",
    "        when(\n",
    "            col(\"priority_rank\") <= lit(DAILY_INVESTIGATION_CAPACITY),\n",
    "            1\n",
    "        ).otherwise(0)\n",
    "    )\n",
    "    # Add decision explanation for interpretability\n",
    "    .withColumn(\n",
    "        \"decision_reason\",\n",
    "        when(\n",
    "            col(\"decision\") == 1,\n",
    "            \"Within capacity, positive expected savings\"\n",
    "        ).when(\n",
    "            col(\"expected_savings_if_investigated\") <= 0,\n",
    "            \"Negative expected savings\"\n",
    "        ).otherwise(\n",
    "            \"Below capacity threshold\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Decision summary\n",
    "print(\"DECISION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "final_df.groupBy(\"decision\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    spark_round(avg(\"risk_probability\"), 3).alias(\"avg_risk\"),\n",
    "    spark_round(spark_sum(\"expected_savings_if_investigated\"), 2).alias(\"total_expected_savings\")\n",
    ").orderBy(col(\"decision\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "046621ea-403f-4ba6-aabe-4b3b3baf105c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Final Gold output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce1d821b-745b-496d-8d3f-ea40706b631c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select columns for Gold table\n",
    "gold_df = final_df.select(\n",
    "    \"case_id\",\n",
    "    \"risk_probability\",\n",
    "    \"investigation_cost\",\n",
    "    \"fraud_loss_if_missed\",\n",
    "    \"expected_loss_if_ignored\",\n",
    "    \"expected_savings_if_investigated\",\n",
    "    \"priority_rank\",\n",
    "    \"decision\",\n",
    "    \"decision_reason\"\n",
    ")\n",
    "\n",
    "# Validate output\n",
    "print(\"GOLD TABLE SCHEMA\")\n",
    "gold_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37807f1e-4585-4230-9aa9-84cd7c149ca8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Write Gold Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c43d0b11-86b8-41ae-8f99-70eb7cf84375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    gold_df\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(GOLD_TABLE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1577a5c5-52be-4cd9-bdca-e66e236a01c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(gold_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fad2c369-72ed-4910-8c0d-bf2eac76c486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Preview Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55048fdb-f565-4eff-b127-393913f3b77d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {GOLD_TABLE}\n",
    "    ORDER BY expected_savings_if_investigated DESC\n",
    "    LIMIT 10\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a74a9b22-a127-41c5-86f5-b4d44b9b07bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Baseline Comparison: Cost-Aware vs Risk-First\n",
    "\n",
    "Let's prove that our approach outperforms the traditional \"highest risk first\" strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d9aabeb-f580-4a80-94fa-49988ff38c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compare strategies\n",
    "comparison_df = spark.sql(f\"\"\"\n",
    "    WITH ranked_data AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            ROW_NUMBER() OVER (ORDER BY expected_savings_if_investigated DESC) AS cost_aware_rank,\n",
    "            ROW_NUMBER() OVER (ORDER BY risk_probability DESC) AS risk_first_rank\n",
    "        FROM {GOLD_TABLE}\n",
    "    )\n",
    "    SELECT\n",
    "        'Cost-Aware (Ours)' AS strategy,\n",
    "        ROUND(SUM(CASE WHEN cost_aware_rank <= {DAILY_INVESTIGATION_CAPACITY} \n",
    "                       THEN expected_savings_if_investigated ELSE 0 END), 2) AS total_savings\n",
    "    FROM ranked_data\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT\n",
    "        'Risk-First (Baseline)' AS strategy,\n",
    "        ROUND(SUM(CASE WHEN risk_first_rank <= {DAILY_INVESTIGATION_CAPACITY} \n",
    "                       THEN expected_savings_if_investigated ELSE 0 END), 2)\n",
    "    FROM ranked_data\n",
    "\"\"\")\n",
    "\n",
    "comparison_pdf = comparison_df.toPandas()\n",
    "\n",
    "# Calculate improvement\n",
    "our_savings = comparison_pdf[comparison_pdf['strategy'] == 'Cost-Aware (Ours)']['total_savings'].values[0]\n",
    "baseline_savings = comparison_pdf[comparison_pdf['strategy'] == 'Risk-First (Baseline)']['total_savings'].values[0]\n",
    "improvement = (our_savings - baseline_savings) / baseline_savings * 100\n",
    "\n",
    "print(\"STRATEGY COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "display(comparison_df)\n",
    "print(f\"\\nImprovement: {improvement:.1f}% more savings with Cost-Aware approach!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "102aa40f-60e8-4130-b45b-5fb275fd7149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Key Takeaways\n",
    "\n",
    "### What We Built\n",
    "1. **Cost-aware decision engine** that optimizes for business value\n",
    "2. **Capacity-constrained optimization** reflecting real-world limitations\n",
    "3. **Transparent decision logic** with explainable rankings\n",
    "\n",
    "### Business Value Delivered\n",
    "- Maximizes expected savings given limited resources\n",
    "- Outperforms traditional risk-first prioritization\n",
    "- Provides actionable recommendations, not just scores\n",
    "\n",
    "\n",
    "---\n",
    "**Next**: See `05_Gold_Analytics_and_Insights` for business impact analysis"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Cost_Aware_Decision_Logic",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
